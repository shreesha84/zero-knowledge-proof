# Zero-Knowledge Neural Network Ownership Verification

This project implements a **replay-safe cryptographic protocol** for verifying ownership of a neural network model using:

* deterministic weight corruption
* challenge–response authentication
* zero-knowledge proofs (via `ezkl`)
* ONNX inference consistency checks

The verifier can confirm that a prover owns the original model **without learning the model weights**.

---

## Features

* Deterministic secret weight indexing using HMAC
* Model corruption and restoration protocol
* ONNX inference validation (L2 output difference)
* Zero-knowledge proof of correct model execution
* Replay-protected interactive protocol
* Fully reproducible setup
* No model or keys committed to GitHub

---

## Architecture

```
Verifier  ──challenge──▶  Prover
Verifier  ◀──report + ZK proof──  Prover
```

The prover demonstrates ownership by:

1. Running inference on the clean model
2. Corrupting secret weights determined by (secret_key, challenge)
3. Showing measurable output change
4. Restoring the model
5. Producing a ZK proof of correct execution

---

## Requirements

* Python 3.10+
* Linux or macOS
* 8GB RAM recommended
* Rust (for ezkl)
* Internet connection (first setup only)

---

## Installation

```bash
git clone https://github.com/shreesha84/zero-knowledge-proof
cd zero-knowledge-proof

python -m venv env
source env/bin/activate

pip install -r requirements.txt
```

Install ezkl:

```bash
pip install ezkl
```

---

## One-Command Setup (Generates everything)
Ensure rustc and cargo are installed in the environment in which you are running the code
```bash
sudo apt install cargo
```
```bash
sudo apt install rustc
```

### Note for WSL Users : Run the following code before running the setup

```bash
# Install dos2unix if you don't have it
sudo apt-get update && sudo apt-get install dos2unix

# Convert the script
dos2unix setup_ezkl.sh
```

### Setup:
```bash
bash scripts/setup_ezkl.sh
```
*If you get ezkl not installed, run this command*
```bash
curl https://raw.githubusercontent.com/zkonduit/ezkl/main/install_ezkl_cli.sh | bash
```
This will automatically:

* generate a large ONNX model
* compile the circuit
* generate SRS
* generate proving + verification keys
* validate the installation

No manual steps required.

---

## Running the Protocol Demo

Open **two terminals**.

---

### Terminal 1 — Verifier

```bash
source env/bin/activate
python backend/verifier_app.py
```

You will see:

```
Session ID: ...
Challenge: ...
Waiting for prover...
```

---

### Terminal 2 — Prover

```bash
source env/bin/activate
python backend/prover_app.py
```

Expected output:

* challenge received
* corruption report
* proof generated
* model restored

---

### Verifier output

```
ZK proof valid
Challenge verified
Session valid
Corruption confirmed
Ownership protocol completed successfully
```

---

## Protocol Security

The protocol provides:

* Ownership verification without revealing weights
* Deterministic secret weight selection
* Replay protection (session_id + timestamp)
* Proof soundness via zk-SNARKs
* Resistance to model substitution attacks (optional extension)

---

## File Structure

```
backend/
  ownership/
    protocol.py
    corrupt.py
    restore.py
    derive_indices.py
    weight_index.py
    ezkl_utils.py
  prover_app.py
  verifier_app.py
  create_big_model.py
  input.json

scripts/
  setup_ezkl.sh
  validate_install.py
```

---

## Reproducibility

No models, keys, proofs, or circuits are committed.

Everything is deterministically generated by:

```bash
bash scripts/setup_ezkl.sh
```

You can verify installation with:

```bash
python scripts/validate_install.py
```

---

## Threat Model (Summary)

| Adversary         | Outcome           |
| ----------------- | ----------------- |
| Passive observer  | learns nothing    |
| Replay attacker   | rejected          |
| Model thief       | fails challenge   |
| Verifier cheating | no weight leakage |

---

## Known Limitations

* Proof generation is computationally expensive
* Only feed-forward models tested
* Fixed input shape required
* Demo uses local file communication

---

## Future Work

* Model hash binding into proof
* Web interface
* Docker deployment
* Performance benchmarking suite
* Support for CNNs and transformers

---

## License

MIT License

---
